{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TFLite model to PyTorch\n",
    "\n",
    "This uses the model **face_detection_front.tflite** from [MediaPipe](https://github.com/google/mediapipe/tree/master/mediapipe/models).\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "1) Clone the MediaPipe repo:\n",
    "\n",
    "```\n",
    "git clone https://github.com/google/mediapipe.git\n",
    "```\n",
    "\n",
    "2) Install **flatbuffers**:\n",
    "\n",
    "```\n",
    "git clone https://github.com/google/flatbuffers.git\n",
    "cmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release\n",
    "make -j\n",
    "\n",
    "cd flatbuffers/python\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "3) Clone the TensorFlow repo. We only need this to get the FlatBuffers schema files (I guess you could just download [schema.fbs](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs)).\n",
    "\n",
    "```\n",
    "git clone https://github.com/tensorflow/tensorflow.git\n",
    "```\n",
    "\n",
    "4) Convert the schema files to Python files using **flatc**:\n",
    "\n",
    "```\n",
    "./flatbuffers/flatc --python tensorflow/tensorflow/lite/schema/schema.fbs\n",
    "```\n",
    "\n",
    "Now we can use the Python FlatBuffer API to read the TFLite file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/google/mediapipe.git\n",
    "# !git clone https://github.com/google/flatbuffers.git\n",
    "# !cd flatbuffers ; cmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release ; make -j\n",
    "# !cd flatbuffers/python ; python setup.py install\n",
    "# !git clone https://github.com/tensorflow/tensorflow.git\n",
    "# !./flatbuffers/flatc --python tensorflow/tensorflow/lite/schema/schema.fbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restart this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the weights from the TFLite file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TFLite model using the FlatBuffers library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite import Model\n",
    "\n",
    "# taken from arcore pod\n",
    "data = open(\"./mediapipe/mediapipe/models/facemesh-lite.f16.tflite\", \"rb\").read()\n",
    "model = Model.Model.GetRootAsModel(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'facemesh-lite.tflite.no_meta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph = model.Subgraphs(0)\n",
    "subgraph.Name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(tensor):\n",
    "    return [tensor.Shape(i) for i in range(tensor.ShapeLength())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the tensors in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0                     b'input_1' 0  0 [1, 192, 192, 3]\n",
      "  1             b'conv2d_1/Kernel' 1  1 [16, 3, 3, 3]\n",
      "  2               b'conv2d_1/Bias' 1  2 [16]\n",
      "  3                    b'conv2d_1' 0  0 [1, 96, 96, 16]\n",
      "  4             b'p_re_lu_1/Alpha' 1  3 [1, 1, 16]\n",
      "  5                   b'p_re_lu_1' 0  0 [1, 96, 96, 16]\n",
      "  6   b'depthwise_conv2d_1/Kernel' 1  4 [1, 3, 3, 16]\n",
      "  7     b'depthwise_conv2d_1/Bias' 1  5 [16]\n",
      "  8          b'depthwise_conv2d_1' 0  0 [1, 96, 96, 16]\n",
      "  9             b'conv2d_2/Kernel' 1  6 [16, 1, 1, 16]\n",
      " 10               b'conv2d_2/Bias' 1  7 [16]\n",
      " 11                    b'conv2d_2' 0  0 [1, 96, 96, 16]\n",
      " 12                       b'add_1' 0  0 [1, 96, 96, 16]\n",
      " 13             b'p_re_lu_2/Alpha' 1  8 [1, 1, 16]\n",
      " 14                   b'p_re_lu_2' 0  0 [1, 96, 96, 16]\n",
      " 15   b'depthwise_conv2d_2/Kernel' 1  9 [1, 3, 3, 16]\n",
      " 16     b'depthwise_conv2d_2/Bias' 1 10 [16]\n",
      " 17          b'depthwise_conv2d_2' 0  0 [1, 96, 96, 16]\n",
      " 18             b'conv2d_3/Kernel' 1 11 [16, 1, 1, 16]\n",
      " 19               b'conv2d_3/Bias' 1 12 [16]\n",
      " 20                    b'conv2d_3' 0  0 [1, 96, 96, 16]\n",
      " 21                       b'add_2' 0  0 [1, 96, 96, 16]\n",
      " 22             b'p_re_lu_3/Alpha' 1 13 [1, 1, 16]\n",
      " 23                   b'p_re_lu_3' 0  0 [1, 96, 96, 16]\n",
      " 24   b'depthwise_conv2d_3/Kernel' 1 14 [1, 3, 3, 16]\n",
      " 25     b'depthwise_conv2d_3/Bias' 1 15 [16]\n",
      " 26          b'depthwise_conv2d_3' 0  0 [1, 48, 48, 16]\n",
      " 27             b'max_pooling2d_1' 0  0 [1, 48, 48, 16]\n",
      " 28             b'conv2d_4/Kernel' 1 16 [32, 1, 1, 16]\n",
      " 29               b'conv2d_4/Bias' 1 17 [32]\n",
      " 30                    b'conv2d_4' 0  0 [1, 48, 48, 32]\n",
      " 31  b'channel_padding_1/Paddings' 2 18 [4, 2]\n",
      " 32           b'channel_padding_1' 0  0 [1, 48, 48, 32]\n",
      " 33                       b'add_3' 0  0 [1, 48, 48, 32]\n",
      " 34             b'p_re_lu_4/Alpha' 1 19 [1, 1, 32]\n",
      " 35                   b'p_re_lu_4' 0  0 [1, 48, 48, 32]\n",
      " 36   b'depthwise_conv2d_4/Kernel' 1 20 [1, 3, 3, 32]\n",
      " 37     b'depthwise_conv2d_4/Bias' 1 21 [32]\n",
      " 38          b'depthwise_conv2d_4' 0  0 [1, 48, 48, 32]\n",
      " 39             b'conv2d_5/Kernel' 1 22 [32, 1, 1, 32]\n",
      " 40               b'conv2d_5/Bias' 1 23 [32]\n",
      " 41                    b'conv2d_5' 0  0 [1, 48, 48, 32]\n",
      " 42                       b'add_4' 0  0 [1, 48, 48, 32]\n",
      " 43             b'p_re_lu_5/Alpha' 1 24 [1, 1, 32]\n",
      " 44                   b'p_re_lu_5' 0  0 [1, 48, 48, 32]\n",
      " 45   b'depthwise_conv2d_5/Kernel' 1 25 [1, 3, 3, 32]\n",
      " 46     b'depthwise_conv2d_5/Bias' 1 26 [32]\n",
      " 47          b'depthwise_conv2d_5' 0  0 [1, 48, 48, 32]\n",
      " 48             b'conv2d_6/Kernel' 1 27 [32, 1, 1, 32]\n",
      " 49               b'conv2d_6/Bias' 1 28 [32]\n",
      " 50                    b'conv2d_6' 0  0 [1, 48, 48, 32]\n",
      " 51                       b'add_5' 0  0 [1, 48, 48, 32]\n",
      " 52             b'p_re_lu_6/Alpha' 1 29 [1, 1, 32]\n",
      " 53                   b'p_re_lu_6' 0  0 [1, 48, 48, 32]\n",
      " 54   b'depthwise_conv2d_6/Kernel' 1 30 [1, 3, 3, 32]\n",
      " 55     b'depthwise_conv2d_6/Bias' 1 31 [32]\n",
      " 56          b'depthwise_conv2d_6' 0  0 [1, 24, 24, 32]\n",
      " 57             b'max_pooling2d_2' 0  0 [1, 24, 24, 32]\n",
      " 58             b'conv2d_7/Kernel' 1 32 [64, 1, 1, 32]\n",
      " 59               b'conv2d_7/Bias' 1 33 [64]\n",
      " 60                    b'conv2d_7' 0  0 [1, 24, 24, 64]\n",
      " 61  b'channel_padding_2/Paddings' 2 34 [4, 2]\n",
      " 62           b'channel_padding_2' 0  0 [1, 24, 24, 64]\n",
      " 63                       b'add_6' 0  0 [1, 24, 24, 64]\n",
      " 64             b'p_re_lu_7/Alpha' 1 35 [1, 1, 64]\n",
      " 65                   b'p_re_lu_7' 0  0 [1, 24, 24, 64]\n",
      " 66   b'depthwise_conv2d_7/Kernel' 1 36 [1, 3, 3, 64]\n",
      " 67     b'depthwise_conv2d_7/Bias' 1 37 [64]\n",
      " 68          b'depthwise_conv2d_7' 0  0 [1, 24, 24, 64]\n",
      " 69             b'conv2d_8/Kernel' 1 38 [64, 1, 1, 64]\n",
      " 70               b'conv2d_8/Bias' 1 39 [64]\n",
      " 71                    b'conv2d_8' 0  0 [1, 24, 24, 64]\n",
      " 72                       b'add_7' 0  0 [1, 24, 24, 64]\n",
      " 73             b'p_re_lu_8/Alpha' 1 40 [1, 1, 64]\n",
      " 74                   b'p_re_lu_8' 0  0 [1, 24, 24, 64]\n",
      " 75   b'depthwise_conv2d_8/Kernel' 1 41 [1, 3, 3, 64]\n",
      " 76     b'depthwise_conv2d_8/Bias' 1 42 [64]\n",
      " 77          b'depthwise_conv2d_8' 0  0 [1, 24, 24, 64]\n",
      " 78             b'conv2d_9/Kernel' 1 43 [64, 1, 1, 64]\n",
      " 79               b'conv2d_9/Bias' 1 44 [64]\n",
      " 80                    b'conv2d_9' 0  0 [1, 24, 24, 64]\n",
      " 81                       b'add_8' 0  0 [1, 24, 24, 64]\n",
      " 82             b'p_re_lu_9/Alpha' 1 45 [1, 1, 64]\n",
      " 83                   b'p_re_lu_9' 0  0 [1, 24, 24, 64]\n",
      " 84   b'depthwise_conv2d_9/Kernel' 1 46 [1, 3, 3, 64]\n",
      " 85     b'depthwise_conv2d_9/Bias' 1 47 [64]\n",
      " 86          b'depthwise_conv2d_9' 0  0 [1, 12, 12, 64]\n",
      " 87             b'max_pooling2d_3' 0  0 [1, 12, 12, 64]\n",
      " 88            b'conv2d_10/Kernel' 1 48 [128, 1, 1, 64]\n",
      " 89              b'conv2d_10/Bias' 1 49 [128]\n",
      " 90                   b'conv2d_10' 0  0 [1, 12, 12, 128]\n",
      " 91  b'channel_padding_3/Paddings' 2 50 [4, 2]\n",
      " 92           b'channel_padding_3' 0  0 [1, 12, 12, 128]\n",
      " 93                       b'add_9' 0  0 [1, 12, 12, 128]\n",
      " 94            b'p_re_lu_10/Alpha' 1 51 [1, 1, 128]\n",
      " 95                  b'p_re_lu_10' 0  0 [1, 12, 12, 128]\n",
      " 96  b'depthwise_conv2d_10/Kernel' 1 52 [1, 3, 3, 128]\n",
      " 97    b'depthwise_conv2d_10/Bias' 1 53 [128]\n",
      " 98         b'depthwise_conv2d_10' 0  0 [1, 12, 12, 128]\n",
      " 99            b'conv2d_11/Kernel' 1 54 [128, 1, 1, 128]\n",
      "100              b'conv2d_11/Bias' 1 55 [128]\n",
      "101                   b'conv2d_11' 0  0 [1, 12, 12, 128]\n",
      "102                      b'add_10' 0  0 [1, 12, 12, 128]\n",
      "103            b'p_re_lu_11/Alpha' 1 56 [1, 1, 128]\n",
      "104                  b'p_re_lu_11' 0  0 [1, 12, 12, 128]\n",
      "105  b'depthwise_conv2d_11/Kernel' 1 57 [1, 3, 3, 128]\n",
      "106    b'depthwise_conv2d_11/Bias' 1 58 [128]\n",
      "107         b'depthwise_conv2d_11' 0  0 [1, 12, 12, 128]\n",
      "108            b'conv2d_12/Kernel' 1 59 [128, 1, 1, 128]\n",
      "109              b'conv2d_12/Bias' 1 60 [128]\n",
      "110                   b'conv2d_12' 0  0 [1, 12, 12, 128]\n",
      "111                      b'add_11' 0  0 [1, 12, 12, 128]\n",
      "112            b'p_re_lu_12/Alpha' 1 61 [1, 1, 128]\n",
      "113                  b'p_re_lu_12' 0  0 [1, 12, 12, 128]\n",
      "114  b'depthwise_conv2d_12/Kernel' 1 62 [1, 3, 3, 128]\n",
      "115    b'depthwise_conv2d_12/Bias' 1 63 [128]\n",
      "116         b'depthwise_conv2d_12' 0  0 [1, 6, 6, 128]\n",
      "117            b'conv2d_13/Kernel' 1 64 [128, 1, 1, 128]\n",
      "118              b'conv2d_13/Bias' 1 65 [128]\n",
      "119                   b'conv2d_13' 0  0 [1, 6, 6, 128]\n",
      "120             b'max_pooling2d_4' 0  0 [1, 6, 6, 128]\n",
      "121                      b'add_12' 0  0 [1, 6, 6, 128]\n",
      "122            b'p_re_lu_13/Alpha' 1 66 [1, 1, 128]\n",
      "123                  b'p_re_lu_13' 0  0 [1, 6, 6, 128]\n",
      "124  b'depthwise_conv2d_13/Kernel' 1 67 [1, 3, 3, 128]\n",
      "125    b'depthwise_conv2d_13/Bias' 1 68 [128]\n",
      "126         b'depthwise_conv2d_13' 0  0 [1, 6, 6, 128]\n",
      "127            b'conv2d_14/Kernel' 1 69 [128, 1, 1, 128]\n",
      "128              b'conv2d_14/Bias' 1 70 [128]\n",
      "129                   b'conv2d_14' 0  0 [1, 6, 6, 128]\n",
      "130                      b'add_13' 0  0 [1, 6, 6, 128]\n",
      "131            b'p_re_lu_14/Alpha' 1 71 [1, 1, 128]\n",
      "132                  b'p_re_lu_14' 0  0 [1, 6, 6, 128]\n",
      "133  b'depthwise_conv2d_14/Kernel' 1 72 [1, 3, 3, 128]\n",
      "134    b'depthwise_conv2d_14/Bias' 1 73 [128]\n",
      "135         b'depthwise_conv2d_14' 0  0 [1, 6, 6, 128]\n",
      "136            b'conv2d_15/Kernel' 1 74 [128, 1, 1, 128]\n",
      "137              b'conv2d_15/Bias' 1 75 [128]\n",
      "138                   b'conv2d_15' 0  0 [1, 6, 6, 128]\n",
      "139                      b'add_14' 0  0 [1, 6, 6, 128]\n",
      "140            b'p_re_lu_15/Alpha' 1 76 [1, 1, 128]\n",
      "141                  b'p_re_lu_15' 0  0 [1, 6, 6, 128]\n",
      "142  b'depthwise_conv2d_15/Kernel' 1 77 [1, 3, 3, 128]\n",
      "143    b'depthwise_conv2d_15/Bias' 1 78 [128]\n",
      "144         b'depthwise_conv2d_15' 0  0 [1, 3, 3, 128]\n",
      "145            b'conv2d_16/Kernel' 1 79 [128, 1, 1, 128]\n",
      "146              b'conv2d_16/Bias' 1 80 [128]\n",
      "147                   b'conv2d_16' 0  0 [1, 3, 3, 128]\n",
      "148             b'max_pooling2d_5' 0  0 [1, 3, 3, 128]\n",
      "149                      b'add_15' 0  0 [1, 3, 3, 128]\n",
      "150            b'p_re_lu_16/Alpha' 1 81 [1, 1, 128]\n",
      "151                  b'p_re_lu_16' 0  0 [1, 3, 3, 128]\n",
      "152  b'depthwise_conv2d_16/Kernel' 1 82 [1, 3, 3, 128]\n",
      "153    b'depthwise_conv2d_16/Bias' 1 83 [128]\n",
      "154         b'depthwise_conv2d_16' 0  0 [1, 3, 3, 128]\n",
      "155            b'conv2d_17/Kernel' 1 84 [128, 1, 1, 128]\n",
      "156              b'conv2d_17/Bias' 1 85 [128]\n",
      "157                   b'conv2d_17' 0  0 [1, 3, 3, 128]\n",
      "158                      b'add_16' 0  0 [1, 3, 3, 128]\n",
      "159            b'p_re_lu_17/Alpha' 1 86 [1, 1, 128]\n",
      "160                  b'p_re_lu_17' 0  0 [1, 3, 3, 128]\n",
      "161  b'depthwise_conv2d_23/Kernel' 1 87 [1, 3, 3, 128]\n",
      "162    b'depthwise_conv2d_23/Bias' 1 88 [128]\n",
      "163         b'depthwise_conv2d_23' 0  0 [1, 3, 3, 128]\n",
      "164  b'depthwise_conv2d_17/Kernel' 1 89 [1, 3, 3, 128]\n",
      "165    b'depthwise_conv2d_17/Bias' 1 90 [128]\n",
      "166         b'depthwise_conv2d_17' 0  0 [1, 3, 3, 128]\n",
      "167            b'conv2d_28/Kernel' 1 91 [128, 1, 1, 128]\n",
      "168              b'conv2d_28/Bias' 1 92 [128]\n",
      "169                   b'conv2d_28' 0  0 [1, 3, 3, 128]\n",
      "170            b'conv2d_18/Kernel' 1 93 [128, 1, 1, 128]\n",
      "171              b'conv2d_18/Bias' 1 94 [128]\n",
      "172                   b'conv2d_18' 0  0 [1, 3, 3, 128]\n",
      "173             b'max_pooling2d_7' 0  0 [1, 3, 3, 128]\n",
      "174                      b'add_23' 0  0 [1, 3, 3, 128]\n",
      "175                      b'add_17' 0  0 [1, 3, 3, 128]\n",
      "176            b'p_re_lu_26/Alpha' 1 95 [1, 1, 128]\n",
      "177                  b'p_re_lu_26' 0  0 [1, 3, 3, 128]\n",
      "178            b'p_re_lu_18/Alpha' 1 96 [1, 1, 128]\n",
      "179                  b'p_re_lu_18' 0  0 [1, 3, 3, 128]\n",
      "180            b'conv2d_29/Kernel' 1 97 [32, 1, 1, 128]\n",
      "181              b'conv2d_29/Bias' 1 98 [32]\n",
      "182                   b'conv2d_29' 0  0 [1, 3, 3, 32]\n",
      "183            b'conv2d_19/Kernel' 1 99 [32, 1, 1, 128]\n",
      "184              b'conv2d_19/Bias' 1 100 [32]\n",
      "185                   b'conv2d_19' 0  0 [1, 3, 3, 32]\n",
      "186            b'p_re_lu_27/Alpha' 1 101 [1, 1, 32]\n",
      "187                  b'p_re_lu_27' 0  0 [1, 3, 3, 32]\n",
      "188            b'p_re_lu_19/Alpha' 1 102 [1, 1, 32]\n",
      "189                  b'p_re_lu_19' 0  0 [1, 3, 3, 32]\n",
      "190  b'depthwise_conv2d_24/Kernel' 1 103 [1, 3, 3, 32]\n",
      "191    b'depthwise_conv2d_24/Bias' 1 104 [32]\n",
      "192         b'depthwise_conv2d_24' 0  0 [1, 3, 3, 32]\n",
      "193  b'depthwise_conv2d_18/Kernel' 1 105 [1, 3, 3, 32]\n",
      "194    b'depthwise_conv2d_18/Bias' 1 106 [32]\n",
      "195         b'depthwise_conv2d_18' 0  0 [1, 3, 3, 32]\n",
      "196            b'conv2d_30/Kernel' 1 107 [32, 1, 1, 32]\n",
      "197              b'conv2d_30/Bias' 1 108 [32]\n",
      "198                   b'conv2d_30' 0  0 [1, 3, 3, 32]\n",
      "199            b'conv2d_20/Kernel' 1 109 [32, 1, 1, 32]\n",
      "200              b'conv2d_20/Bias' 1 110 [32]\n",
      "201                   b'conv2d_20' 0  0 [1, 3, 3, 32]\n",
      "202                      b'add_24' 0  0 [1, 3, 3, 32]\n",
      "203                      b'add_18' 0  0 [1, 3, 3, 32]\n",
      "204            b'p_re_lu_28/Alpha' 1 111 [1, 1, 32]\n",
      "205                  b'p_re_lu_28' 0  0 [1, 3, 3, 32]\n",
      "206            b'p_re_lu_20/Alpha' 1 112 [1, 1, 32]\n",
      "207                  b'p_re_lu_20' 0  0 [1, 3, 3, 32]\n",
      "208            b'conv2d_31/Kernel' 1 113 [1, 3, 3, 32]\n",
      "209              b'conv2d_31/Bias' 1 114 [1]\n",
      "210                   b'conv2d_31' 0  0 [1, 1, 1, 1]\n",
      "211            b'conv2d_21/Kernel' 1 115 [1404, 3, 3, 32]\n",
      "212              b'conv2d_21/Bias' 1 116 [1404]\n",
      "213                   b'conv2d_21' 0  0 [1, 1, 1, 1404]\n",
      "214 b'depthwise_conv2d_14/Bias_dequantize' 0  0 [128]\n",
      "215    b'conv2d_3/Bias_dequantize' 0  0 [16]\n",
      "216 b'conv2d_18/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "217 b'depthwise_conv2d_11/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "218   b'conv2d_19/Bias_dequantize' 0  0 [32]\n",
      "219  b'conv2d_8/Kernel_dequantize' 0  0 [64, 1, 1, 64]\n",
      "220   b'conv2d_17/Bias_dequantize' 0  0 [128]\n",
      "221 b'depthwise_conv2d_9/Kernel_dequantize' 0  0 [1, 3, 3, 64]\n",
      "222 b'conv2d_14/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "223  b'conv2d_6/Kernel_dequantize' 0  0 [32, 1, 1, 32]\n",
      "224 b'conv2d_20/Kernel_dequantize' 0  0 [32, 1, 1, 32]\n",
      "225 b'depthwise_conv2d_6/Bias_dequantize' 0  0 [32]\n",
      "226 b'p_re_lu_20/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "227 b'p_re_lu_18/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "228 b'conv2d_11/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "229 b'depthwise_conv2d_11/Bias_dequantize' 0  0 [128]\n",
      "230 b'depthwise_conv2d_15/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "231  b'p_re_lu_4/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "232    b'conv2d_8/Bias_dequantize' 0  0 [64]\n",
      "233 b'depthwise_conv2d_9/Bias_dequantize' 0  0 [64]\n",
      "234  b'p_re_lu_2/Alpha_dequantize' 0  0 [1, 1, 16]\n",
      "235 b'depthwise_conv2d_17/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "236    b'conv2d_6/Bias_dequantize' 0  0 [32]\n",
      "237   b'conv2d_20/Bias_dequantize' 0  0 [32]\n",
      "238   b'conv2d_14/Bias_dequantize' 0  0 [128]\n",
      "239   b'conv2d_18/Bias_dequantize' 0  0 [128]\n",
      "240 b'depthwise_conv2d_15/Bias_dequantize' 0  0 [128]\n",
      "241  b'conv2d_4/Kernel_dequantize' 0  0 [32, 1, 1, 16]\n",
      "242 b'p_re_lu_27/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "243 b'depthwise_conv2d_12/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "244 b'p_re_lu_16/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "245 b'depthwise_conv2d_1/Kernel_dequantize' 0  0 [1, 3, 3, 16]\n",
      "246 b'depthwise_conv2d_18/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "247  b'conv2d_9/Kernel_dequantize' 0  0 [64, 1, 1, 64]\n",
      "248 b'depthwise_conv2d_17/Bias_dequantize' 0  0 [128]\n",
      "249 b'conv2d_31/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "250 b'conv2d_15/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "251  b'p_re_lu_7/Alpha_dequantize' 0  0 [1, 1, 64]\n",
      "252   b'conv2d_11/Bias_dequantize' 0  0 [128]\n",
      "253 b'depthwise_conv2d_4/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "254 b'conv2d_12/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "255 b'depthwise_conv2d_12/Bias_dequantize' 0  0 [128]\n",
      "256 b'depthwise_conv2d_18/Bias_dequantize' 0  0 [32]\n",
      "257 b'depthwise_conv2d_1/Bias_dequantize' 0  0 [16]\n",
      "258    b'conv2d_9/Bias_dequantize' 0  0 [64]\n",
      "259  b'p_re_lu_5/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "260 b'p_re_lu_13/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "261 b'p_re_lu_10/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "262   b'conv2d_15/Bias_dequantize' 0  0 [128]\n",
      "263  b'p_re_lu_3/Alpha_dequantize' 0  0 [1, 1, 16]\n",
      "264   b'conv2d_31/Bias_dequantize' 0  0 [1]\n",
      "265  b'conv2d_7/Kernel_dequantize' 0  0 [64, 1, 1, 32]\n",
      "266    b'conv2d_4/Bias_dequantize' 0  0 [32]\n",
      "267 b'conv2d_29/Kernel_dequantize' 0  0 [32, 1, 1, 128]\n",
      "268 b'depthwise_conv2d_16/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "269  b'conv2d_1/Kernel_dequantize' 0  0 [16, 3, 3, 3]\n",
      "270 b'p_re_lu_17/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "271 b'depthwise_conv2d_2/Kernel_dequantize' 0  0 [1, 3, 3, 16]\n",
      "272    b'conv2d_7/Bias_dequantize' 0  0 [64]\n",
      "273 b'depthwise_conv2d_7/Kernel_dequantize' 0  0 [1, 3, 3, 64]\n",
      "274 b'conv2d_16/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "275   b'conv2d_29/Bias_dequantize' 0  0 [32]\n",
      "276 b'depthwise_conv2d_4/Bias_dequantize' 0  0 [32]\n",
      "277  b'p_re_lu_8/Alpha_dequantize' 0  0 [1, 1, 64]\n",
      "278 b'p_re_lu_19/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "279   b'conv2d_12/Bias_dequantize' 0  0 [128]\n",
      "280 b'conv2d_30/Kernel_dequantize' 0  0 [32, 1, 1, 32]\n",
      "281 b'depthwise_conv2d_5/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "282 b'depthwise_conv2d_13/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "283  b'conv2d_2/Kernel_dequantize' 0  0 [16, 1, 1, 16]\n",
      "284 b'conv2d_28/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "285 b'depthwise_conv2d_2/Bias_dequantize' 0  0 [16]\n",
      "286  b'p_re_lu_6/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "287 b'conv2d_10/Kernel_dequantize' 0  0 [128, 1, 1, 64]\n",
      "288 b'p_re_lu_14/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "289 b'depthwise_conv2d_7/Bias_dequantize' 0  0 [64]\n",
      "290 b'p_re_lu_11/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "291   b'conv2d_16/Bias_dequantize' 0  0 [128]\n",
      "292 b'conv2d_13/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "293 b'depthwise_conv2d_16/Bias_dequantize' 0  0 [128]\n",
      "294    b'conv2d_1/Bias_dequantize' 0  0 [16]\n",
      "295 b'depthwise_conv2d_13/Bias_dequantize' 0  0 [128]\n",
      "296 b'depthwise_conv2d_23/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "297    b'conv2d_2/Bias_dequantize' 0  0 [16]\n",
      "298 b'p_re_lu_28/Alpha_dequantize' 0  0 [1, 1, 32]\n",
      "299   b'conv2d_10/Bias_dequantize' 0  0 [128]\n",
      "300 b'depthwise_conv2d_10/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "301   b'conv2d_28/Bias_dequantize' 0  0 [128]\n",
      "302 b'depthwise_conv2d_3/Kernel_dequantize' 0  0 [1, 3, 3, 16]\n",
      "303 b'conv2d_21/Kernel_dequantize' 0  0 [1404, 3, 3, 32]\n",
      "304 b'conv2d_19/Kernel_dequantize' 0  0 [32, 1, 1, 128]\n",
      "305 b'depthwise_conv2d_8/Kernel_dequantize' 0  0 [1, 3, 3, 64]\n",
      "306  b'conv2d_5/Kernel_dequantize' 0  0 [32, 1, 1, 32]\n",
      "307 b'depthwise_conv2d_5/Bias_dequantize' 0  0 [32]\n",
      "308 b'depthwise_conv2d_24/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "309  b'p_re_lu_9/Alpha_dequantize' 0  0 [1, 1, 64]\n",
      "310   b'conv2d_13/Bias_dequantize' 0  0 [128]\n",
      "311   b'conv2d_30/Bias_dequantize' 0  0 [32]\n",
      "312 b'depthwise_conv2d_6/Kernel_dequantize' 0  0 [1, 3, 3, 32]\n",
      "313 b'depthwise_conv2d_10/Bias_dequantize' 0  0 [128]\n",
      "314 b'depthwise_conv2d_14/Kernel_dequantize' 0  0 [1, 3, 3, 128]\n",
      "315  b'conv2d_3/Kernel_dequantize' 0  0 [16, 1, 1, 16]\n",
      "316 b'depthwise_conv2d_3/Bias_dequantize' 0  0 [16]\n",
      "317 b'p_re_lu_26/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "318   b'conv2d_21/Bias_dequantize' 0  0 [1404]\n",
      "319 b'p_re_lu_15/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "320 b'depthwise_conv2d_8/Bias_dequantize' 0  0 [64]\n",
      "321 b'p_re_lu_12/Alpha_dequantize' 0  0 [1, 1, 128]\n",
      "322  b'p_re_lu_1/Alpha_dequantize' 0  0 [1, 1, 16]\n",
      "323 b'conv2d_17/Kernel_dequantize' 0  0 [128, 1, 1, 128]\n",
      "324    b'conv2d_5/Bias_dequantize' 0  0 [32]\n",
      "325 b'depthwise_conv2d_24/Bias_dequantize' 0  0 [32]\n",
      "326 b'depthwise_conv2d_23/Bias_dequantize' 0  0 [128]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, subgraph.TensorsLength()):\n",
    "    tensor = subgraph.Tensors(i)\n",
    "    print(\"%3d %30s %d %2d %s\" % (i, tensor.Name(), tensor.Type(), tensor.Buffer(), \n",
    "                                  get_shape(subgraph.Tensors(i))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a look-up table that lets us get the tensor index based on the tensor name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict = {(subgraph.Tensors(i).Name().decode(\"utf8\")): i \n",
    "               for i in range(subgraph.TensorsLength())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab only the tensors that represent weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {}\n",
    "for i in range(subgraph.TensorsLength()):\n",
    "    tensor = subgraph.Tensors(i)\n",
    "    if tensor.Buffer() > 0:\n",
    "        name = tensor.Name().decode(\"utf8\")\n",
    "        parameters[name] = tensor.Buffer()\n",
    "\n",
    "len(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buffers are simply arrays of bytes. As the docs say,\n",
    "\n",
    "> The data_buffer itself is an opaque container, with the assumption that the\n",
    "> target device is little-endian. In addition, all builtin operators assume\n",
    "> the memory is ordered such that if `shape` is [4, 3, 2], then index\n",
    "> [i, j, k] maps to `data_buffer[i*3*2 + j*2 + k]`.\n",
    "\n",
    "For weights and biases, we need to interpret every 4 bytes as being as float. On my machine, the native byte ordering is already little-endian so we don't need to do anything special for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(tensor_name):\n",
    "    i = tensor_dict[tensor_name]\n",
    "    tensor = subgraph.Tensors(i)\n",
    "    buffer = tensor.Buffer()\n",
    "    shape = get_shape(tensor)\n",
    "    assert(tensor.Type() == 1)  # FLOAT16\n",
    "    \n",
    "    W = model.Buffers(buffer).DataAsNumpy()\n",
    "    W = W.view(dtype=np.float16)\n",
    "    W = W.reshape(shape)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 3, 3, 3), (16,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_weights(\"conv2d_1/Kernel\")\n",
    "b = get_weights(\"conv2d_1/Bias\")\n",
    "W.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the weights for all the layers and copy them into our PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the weights to PyTorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from facemesh import FaceMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FaceMesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaceMesh(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): PReLU(num_parameters=16)\n",
       "    (2): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=16)\n",
       "    )\n",
       "    (3): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=16)\n",
       "    )\n",
       "    (4): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16)\n",
       "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (5): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (6): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (7): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), groups=32)\n",
       "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (8): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (9): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (10): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), groups=64)\n",
       "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (11): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (12): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (13): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (14): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (15): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "  )\n",
       "  (coord_head): Sequential(\n",
       "    (0): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (1): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (2): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (3): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): PReLU(num_parameters=32)\n",
       "    (5): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (6): Conv2d(32, 1404, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (conf_head): Sequential(\n",
       "    (0): FaceMeshBlock(\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): PReLU(num_parameters=32)\n",
       "    (3): FaceMeshBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (4): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 193, 193])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1404])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.randn(2,3,192,192))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a lookup table that maps the layer names between the two models. We're going to assume here that the tensors will be in the same order in both models. If not, we should get an error because shapes don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2d_1/Kernel',\n",
       " 'conv2d_1/Bias',\n",
       " 'p_re_lu_1/Alpha',\n",
       " 'depthwise_conv2d_1/Kernel',\n",
       " 'depthwise_conv2d_1/Bias']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probable_names = []\n",
    "for i in range(0, subgraph.TensorsLength()):\n",
    "    tensor = subgraph.Tensors(i)\n",
    "    if tensor.Buffer() > 0 and tensor.Type() == 1:\n",
    "        probable_names.append(tensor.Name().decode(\"utf-8\"))\n",
    "        \n",
    "probable_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conv2d_1/Kernel', 'backbone.0.weight'),\n",
      " ('conv2d_1/Bias', 'backbone.0.bias'),\n",
      " ('p_re_lu_1/Alpha', 'backbone.1.weight'),\n",
      " ('depthwise_conv2d_1/Kernel', 'backbone.2.convs.0.weight'),\n",
      " ('depthwise_conv2d_1/Bias', 'backbone.2.convs.0.bias'),\n",
      " ('conv2d_2/Kernel', 'backbone.2.convs.1.weight'),\n",
      " ('conv2d_2/Bias', 'backbone.2.convs.1.bias'),\n",
      " ('p_re_lu_2/Alpha', 'backbone.2.act.weight'),\n",
      " ('depthwise_conv2d_2/Kernel', 'backbone.3.convs.0.weight'),\n",
      " ('depthwise_conv2d_2/Bias', 'backbone.3.convs.0.bias'),\n",
      " ('conv2d_3/Kernel', 'backbone.3.convs.1.weight'),\n",
      " ('conv2d_3/Bias', 'backbone.3.convs.1.bias'),\n",
      " ('p_re_lu_3/Alpha', 'backbone.3.act.weight'),\n",
      " ('depthwise_conv2d_3/Kernel', 'backbone.4.convs.0.weight'),\n",
      " ('depthwise_conv2d_3/Bias', 'backbone.4.convs.0.bias'),\n",
      " ('conv2d_4/Kernel', 'backbone.4.convs.1.weight'),\n",
      " ('conv2d_4/Bias', 'backbone.4.convs.1.bias'),\n",
      " ('p_re_lu_4/Alpha', 'backbone.4.act.weight'),\n",
      " ('depthwise_conv2d_4/Kernel', 'backbone.5.convs.0.weight'),\n",
      " ('depthwise_conv2d_4/Bias', 'backbone.5.convs.0.bias'),\n",
      " ('conv2d_5/Kernel', 'backbone.5.convs.1.weight'),\n",
      " ('conv2d_5/Bias', 'backbone.5.convs.1.bias'),\n",
      " ('p_re_lu_5/Alpha', 'backbone.5.act.weight'),\n",
      " ('depthwise_conv2d_5/Kernel', 'backbone.6.convs.0.weight'),\n",
      " ('depthwise_conv2d_5/Bias', 'backbone.6.convs.0.bias'),\n",
      " ('conv2d_6/Kernel', 'backbone.6.convs.1.weight'),\n",
      " ('conv2d_6/Bias', 'backbone.6.convs.1.bias'),\n",
      " ('p_re_lu_6/Alpha', 'backbone.6.act.weight'),\n",
      " ('depthwise_conv2d_6/Kernel', 'backbone.7.convs.0.weight'),\n",
      " ('depthwise_conv2d_6/Bias', 'backbone.7.convs.0.bias'),\n",
      " ('conv2d_7/Kernel', 'backbone.7.convs.1.weight'),\n",
      " ('conv2d_7/Bias', 'backbone.7.convs.1.bias'),\n",
      " ('p_re_lu_7/Alpha', 'backbone.7.act.weight'),\n",
      " ('depthwise_conv2d_7/Kernel', 'backbone.8.convs.0.weight'),\n",
      " ('depthwise_conv2d_7/Bias', 'backbone.8.convs.0.bias'),\n",
      " ('conv2d_8/Kernel', 'backbone.8.convs.1.weight'),\n",
      " ('conv2d_8/Bias', 'backbone.8.convs.1.bias'),\n",
      " ('p_re_lu_8/Alpha', 'backbone.8.act.weight'),\n",
      " ('depthwise_conv2d_8/Kernel', 'backbone.9.convs.0.weight'),\n",
      " ('depthwise_conv2d_8/Bias', 'backbone.9.convs.0.bias'),\n",
      " ('conv2d_9/Kernel', 'backbone.9.convs.1.weight'),\n",
      " ('conv2d_9/Bias', 'backbone.9.convs.1.bias'),\n",
      " ('p_re_lu_9/Alpha', 'backbone.9.act.weight'),\n",
      " ('depthwise_conv2d_9/Kernel', 'backbone.10.convs.0.weight'),\n",
      " ('depthwise_conv2d_9/Bias', 'backbone.10.convs.0.bias'),\n",
      " ('conv2d_10/Kernel', 'backbone.10.convs.1.weight'),\n",
      " ('conv2d_10/Bias', 'backbone.10.convs.1.bias'),\n",
      " ('p_re_lu_10/Alpha', 'backbone.10.act.weight'),\n",
      " ('depthwise_conv2d_10/Kernel', 'backbone.11.convs.0.weight'),\n",
      " ('depthwise_conv2d_10/Bias', 'backbone.11.convs.0.bias'),\n",
      " ('conv2d_11/Kernel', 'backbone.11.convs.1.weight'),\n",
      " ('conv2d_11/Bias', 'backbone.11.convs.1.bias'),\n",
      " ('p_re_lu_11/Alpha', 'backbone.11.act.weight'),\n",
      " ('depthwise_conv2d_11/Kernel', 'backbone.12.convs.0.weight'),\n",
      " ('depthwise_conv2d_11/Bias', 'backbone.12.convs.0.bias'),\n",
      " ('conv2d_12/Kernel', 'backbone.12.convs.1.weight'),\n",
      " ('conv2d_12/Bias', 'backbone.12.convs.1.bias'),\n",
      " ('p_re_lu_12/Alpha', 'backbone.12.act.weight'),\n",
      " ('depthwise_conv2d_12/Kernel', 'backbone.13.convs.0.weight'),\n",
      " ('depthwise_conv2d_12/Bias', 'backbone.13.convs.0.bias'),\n",
      " ('conv2d_13/Kernel', 'backbone.13.convs.1.weight'),\n",
      " ('conv2d_13/Bias', 'backbone.13.convs.1.bias'),\n",
      " ('p_re_lu_13/Alpha', 'backbone.13.act.weight'),\n",
      " ('depthwise_conv2d_13/Kernel', 'backbone.14.convs.0.weight'),\n",
      " ('depthwise_conv2d_13/Bias', 'backbone.14.convs.0.bias'),\n",
      " ('conv2d_14/Kernel', 'backbone.14.convs.1.weight'),\n",
      " ('conv2d_14/Bias', 'backbone.14.convs.1.bias'),\n",
      " ('p_re_lu_14/Alpha', 'backbone.14.act.weight'),\n",
      " ('depthwise_conv2d_14/Kernel', 'backbone.15.convs.0.weight'),\n",
      " ('depthwise_conv2d_14/Bias', 'backbone.15.convs.0.bias'),\n",
      " ('conv2d_15/Kernel', 'backbone.15.convs.1.weight'),\n",
      " ('conv2d_15/Bias', 'backbone.15.convs.1.bias'),\n",
      " ('p_re_lu_15/Alpha', 'backbone.15.act.weight'),\n",
      " ('depthwise_conv2d_15/Kernel', 'coord_head.0.convs.0.weight'),\n",
      " ('depthwise_conv2d_15/Bias', 'coord_head.0.convs.0.bias'),\n",
      " ('conv2d_16/Kernel', 'coord_head.0.convs.1.weight'),\n",
      " ('conv2d_16/Bias', 'coord_head.0.convs.1.bias'),\n",
      " ('p_re_lu_16/Alpha', 'coord_head.0.act.weight'),\n",
      " ('depthwise_conv2d_16/Kernel', 'coord_head.1.convs.0.weight'),\n",
      " ('depthwise_conv2d_16/Bias', 'coord_head.1.convs.0.bias'),\n",
      " ('conv2d_17/Kernel', 'coord_head.1.convs.1.weight'),\n",
      " ('conv2d_17/Bias', 'coord_head.1.convs.1.bias'),\n",
      " ('p_re_lu_17/Alpha', 'coord_head.1.act.weight'),\n",
      " ('depthwise_conv2d_23/Kernel', 'coord_head.2.convs.0.weight'),\n",
      " ('depthwise_conv2d_23/Bias', 'coord_head.2.convs.0.bias'),\n",
      " ('depthwise_conv2d_17/Kernel', 'coord_head.2.convs.1.weight'),\n",
      " ('depthwise_conv2d_17/Bias', 'coord_head.2.convs.1.bias'),\n",
      " ('conv2d_28/Kernel', 'coord_head.2.act.weight'),\n",
      " ('conv2d_28/Bias', 'coord_head.3.weight'),\n",
      " ('conv2d_18/Kernel', 'coord_head.3.bias'),\n",
      " ('conv2d_18/Bias', 'coord_head.4.weight'),\n",
      " ('p_re_lu_26/Alpha', 'coord_head.5.convs.0.weight'),\n",
      " ('p_re_lu_18/Alpha', 'coord_head.5.convs.0.bias'),\n",
      " ('conv2d_29/Kernel', 'coord_head.5.convs.1.weight'),\n",
      " ('conv2d_29/Bias', 'coord_head.5.convs.1.bias'),\n",
      " ('conv2d_19/Kernel', 'coord_head.5.act.weight'),\n",
      " ('conv2d_19/Bias', 'coord_head.6.weight'),\n",
      " ('p_re_lu_27/Alpha', 'coord_head.6.bias'),\n",
      " ('p_re_lu_19/Alpha', 'conf_head.0.convs.0.weight'),\n",
      " ('depthwise_conv2d_24/Kernel', 'conf_head.0.convs.0.bias'),\n",
      " ('depthwise_conv2d_24/Bias', 'conf_head.0.convs.1.weight'),\n",
      " ('depthwise_conv2d_18/Kernel', 'conf_head.0.convs.1.bias'),\n",
      " ('depthwise_conv2d_18/Bias', 'conf_head.0.act.weight'),\n",
      " ('conv2d_30/Kernel', 'conf_head.1.weight'),\n",
      " ('conv2d_30/Bias', 'conf_head.1.bias'),\n",
      " ('conv2d_20/Kernel', 'conf_head.2.weight'),\n",
      " ('conv2d_20/Bias', 'conf_head.3.convs.0.weight'),\n",
      " ('p_re_lu_28/Alpha', 'conf_head.3.convs.0.bias'),\n",
      " ('p_re_lu_20/Alpha', 'conf_head.3.convs.1.weight'),\n",
      " ('conv2d_31/Kernel', 'conf_head.3.convs.1.bias'),\n",
      " ('conv2d_31/Bias', 'conf_head.3.act.weight'),\n",
      " ('conv2d_21/Kernel', 'conf_head.4.weight'),\n",
      " ('conv2d_21/Bias', 'conf_head.4.bias')]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(zip(probable_names, net.state_dict())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 113)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.state_dict()), len(probable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = {}\n",
    "i = 0\n",
    "for name, params in net.state_dict().items():\n",
    "    if i < 83:\n",
    "        convert[name] = probable_names[i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mapping = {\n",
    "    'coord_head.2.convs.0.weight': 'depthwise_conv2d_17/Kernel',\n",
    "    'coord_head.2.convs.0.bias': 'depthwise_conv2d_17/Bias',\n",
    "    'coord_head.2.convs.1.weight': 'conv2d_18/Kernel',\n",
    "    'coord_head.2.convs.1.bias': 'conv2d_18/Bias',\n",
    "    'coord_head.2.act.weight': 'p_re_lu_18/Alpha',\n",
    "    'coord_head.3.weight': 'conv2d_19/Kernel',\n",
    "    'coord_head.3.bias': 'conv2d_19/Bias',\n",
    "    'coord_head.4.weight': 'p_re_lu_19/Alpha',\n",
    "    'coord_head.5.convs.0.weight': 'depthwise_conv2d_18/Kernel',\n",
    "    'coord_head.5.convs.0.bias': 'depthwise_conv2d_18/Bias',\n",
    "    'coord_head.5.convs.1.weight': 'conv2d_20/Kernel',\n",
    "    'coord_head.5.convs.1.bias': 'conv2d_20/Bias',\n",
    "    'coord_head.5.act.weight': 'p_re_lu_20/Alpha',\n",
    "    'coord_head.6.weight': 'conv2d_21/Kernel',\n",
    "    'coord_head.6.bias': 'conv2d_21/Bias',\n",
    "    'conf_head.0.convs.0.weight': 'depthwise_conv2d_23/Kernel',\n",
    "    'conf_head.0.convs.0.bias': 'depthwise_conv2d_23/Bias',\n",
    "    'conf_head.0.convs.1.weight': 'conv2d_28/Kernel',\n",
    "    'conf_head.0.convs.1.bias': 'conv2d_28/Bias',\n",
    "    'conf_head.0.act.weight': 'p_re_lu_26/Alpha',\n",
    "    'conf_head.1.weight': 'conv2d_29/Kernel',\n",
    "    'conf_head.1.bias': 'conv2d_29/Bias',\n",
    "    'conf_head.2.weight': 'p_re_lu_27/Alpha',\n",
    "    'conf_head.3.convs.0.weight': 'depthwise_conv2d_24/Kernel',\n",
    "    'conf_head.3.convs.0.bias': 'depthwise_conv2d_24/Bias',\n",
    "    'conf_head.3.convs.1.weight': 'conv2d_30/Kernel',\n",
    "    'conf_head.3.convs.1.bias': 'conv2d_30/Bias',\n",
    "    'conf_head.3.act.weight': 'p_re_lu_28/Alpha',\n",
    "    'conf_head.4.weight': 'conv2d_31/Kernel',\n",
    "    'conf_head.4.bias': 'conv2d_31/Bias'\n",
    "}\n",
    "convert.update(manual_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the weights into the layers.\n",
    "\n",
    "Note that the ordering of the weights is different between PyTorch and TFLite, so we need to transpose them.\n",
    "\n",
    "Convolution weights:\n",
    "\n",
    "    TFLite:  (out_channels, kernel_height, kernel_width, in_channels)\n",
    "    PyTorch: (out_channels, in_channels, kernel_height, kernel_width)\n",
    "\n",
    "Depthwise convolution weights:\n",
    "\n",
    "    TFLite:  (1, kernel_height, kernel_width, channels)\n",
    "    PyTorch: (channels, 1, kernel_height, kernel_width)\n",
    "    \n",
    "PReLU:\n",
    "\n",
    "    TFLite:  (1, 1, num_channels)\n",
    "    PyTorch: (num_channels, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.0.weight conv2d_1/Kernel (16, 3, 3, 3) torch.Size([16, 3, 3, 3])\n",
      "backbone.0.bias conv2d_1/Bias (16,) torch.Size([16])\n",
      "backbone.1.weight p_re_lu_1/Alpha (1, 1, 16) torch.Size([16])\n",
      "backbone.2.convs.0.weight depthwise_conv2d_1/Kernel (1, 3, 3, 16) torch.Size([16, 1, 3, 3])\n",
      "backbone.2.convs.0.bias depthwise_conv2d_1/Bias (16,) torch.Size([16])\n",
      "backbone.2.convs.1.weight conv2d_2/Kernel (16, 1, 1, 16) torch.Size([16, 16, 1, 1])\n",
      "backbone.2.convs.1.bias conv2d_2/Bias (16,) torch.Size([16])\n",
      "backbone.2.act.weight p_re_lu_2/Alpha (1, 1, 16) torch.Size([16])\n",
      "backbone.3.convs.0.weight depthwise_conv2d_2/Kernel (1, 3, 3, 16) torch.Size([16, 1, 3, 3])\n",
      "backbone.3.convs.0.bias depthwise_conv2d_2/Bias (16,) torch.Size([16])\n",
      "backbone.3.convs.1.weight conv2d_3/Kernel (16, 1, 1, 16) torch.Size([16, 16, 1, 1])\n",
      "backbone.3.convs.1.bias conv2d_3/Bias (16,) torch.Size([16])\n",
      "backbone.3.act.weight p_re_lu_3/Alpha (1, 1, 16) torch.Size([16])\n",
      "backbone.4.convs.0.weight depthwise_conv2d_3/Kernel (1, 3, 3, 16) torch.Size([16, 1, 3, 3])\n",
      "backbone.4.convs.0.bias depthwise_conv2d_3/Bias (16,) torch.Size([16])\n",
      "backbone.4.convs.1.weight conv2d_4/Kernel (32, 1, 1, 16) torch.Size([32, 16, 1, 1])\n",
      "backbone.4.convs.1.bias conv2d_4/Bias (32,) torch.Size([32])\n",
      "backbone.4.act.weight p_re_lu_4/Alpha (1, 1, 32) torch.Size([32])\n",
      "backbone.5.convs.0.weight depthwise_conv2d_4/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
      "backbone.5.convs.0.bias depthwise_conv2d_4/Bias (32,) torch.Size([32])\n",
      "backbone.5.convs.1.weight conv2d_5/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
      "backbone.5.convs.1.bias conv2d_5/Bias (32,) torch.Size([32])\n",
      "backbone.5.act.weight p_re_lu_5/Alpha (1, 1, 32) torch.Size([32])\n",
      "backbone.6.convs.0.weight depthwise_conv2d_5/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
      "backbone.6.convs.0.bias depthwise_conv2d_5/Bias (32,) torch.Size([32])\n",
      "backbone.6.convs.1.weight conv2d_6/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
      "backbone.6.convs.1.bias conv2d_6/Bias (32,) torch.Size([32])\n",
      "backbone.6.act.weight p_re_lu_6/Alpha (1, 1, 32) torch.Size([32])\n",
      "backbone.7.convs.0.weight depthwise_conv2d_6/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
      "backbone.7.convs.0.bias depthwise_conv2d_6/Bias (32,) torch.Size([32])\n",
      "backbone.7.convs.1.weight conv2d_7/Kernel (64, 1, 1, 32) torch.Size([64, 32, 1, 1])\n",
      "backbone.7.convs.1.bias conv2d_7/Bias (64,) torch.Size([64])\n",
      "backbone.7.act.weight p_re_lu_7/Alpha (1, 1, 64) torch.Size([64])\n",
      "backbone.8.convs.0.weight depthwise_conv2d_7/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
      "backbone.8.convs.0.bias depthwise_conv2d_7/Bias (64,) torch.Size([64])\n",
      "backbone.8.convs.1.weight conv2d_8/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
      "backbone.8.convs.1.bias conv2d_8/Bias (64,) torch.Size([64])\n",
      "backbone.8.act.weight p_re_lu_8/Alpha (1, 1, 64) torch.Size([64])\n",
      "backbone.9.convs.0.weight depthwise_conv2d_8/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
      "backbone.9.convs.0.bias depthwise_conv2d_8/Bias (64,) torch.Size([64])\n",
      "backbone.9.convs.1.weight conv2d_9/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
      "backbone.9.convs.1.bias conv2d_9/Bias (64,) torch.Size([64])\n",
      "backbone.9.act.weight p_re_lu_9/Alpha (1, 1, 64) torch.Size([64])\n",
      "backbone.10.convs.0.weight depthwise_conv2d_9/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
      "backbone.10.convs.0.bias depthwise_conv2d_9/Bias (64,) torch.Size([64])\n",
      "backbone.10.convs.1.weight conv2d_10/Kernel (128, 1, 1, 64) torch.Size([128, 64, 1, 1])\n",
      "backbone.10.convs.1.bias conv2d_10/Bias (128,) torch.Size([128])\n",
      "backbone.10.act.weight p_re_lu_10/Alpha (1, 1, 128) torch.Size([128])\n",
      "backbone.11.convs.0.weight depthwise_conv2d_10/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "backbone.11.convs.0.bias depthwise_conv2d_10/Bias (128,) torch.Size([128])\n",
      "backbone.11.convs.1.weight conv2d_11/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "backbone.11.convs.1.bias conv2d_11/Bias (128,) torch.Size([128])\n",
      "backbone.11.act.weight p_re_lu_11/Alpha (1, 1, 128) torch.Size([128])\n",
      "backbone.12.convs.0.weight depthwise_conv2d_11/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "backbone.12.convs.0.bias depthwise_conv2d_11/Bias (128,) torch.Size([128])\n",
      "backbone.12.convs.1.weight conv2d_12/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "backbone.12.convs.1.bias conv2d_12/Bias (128,) torch.Size([128])\n",
      "backbone.12.act.weight p_re_lu_12/Alpha (1, 1, 128) torch.Size([128])\n",
      "backbone.13.convs.0.weight depthwise_conv2d_12/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "backbone.13.convs.0.bias depthwise_conv2d_12/Bias (128,) torch.Size([128])\n",
      "backbone.13.convs.1.weight conv2d_13/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "backbone.13.convs.1.bias conv2d_13/Bias (128,) torch.Size([128])\n",
      "backbone.13.act.weight p_re_lu_13/Alpha (1, 1, 128) torch.Size([128])\n",
      "backbone.14.convs.0.weight depthwise_conv2d_13/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "backbone.14.convs.0.bias depthwise_conv2d_13/Bias (128,) torch.Size([128])\n",
      "backbone.14.convs.1.weight conv2d_14/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "backbone.14.convs.1.bias conv2d_14/Bias (128,) torch.Size([128])\n",
      "backbone.14.act.weight p_re_lu_14/Alpha (1, 1, 128) torch.Size([128])\n",
      "backbone.15.convs.0.weight depthwise_conv2d_14/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "backbone.15.convs.0.bias depthwise_conv2d_14/Bias (128,) torch.Size([128])\n",
      "backbone.15.convs.1.weight conv2d_15/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "backbone.15.convs.1.bias conv2d_15/Bias (128,) torch.Size([128])\n",
      "backbone.15.act.weight p_re_lu_15/Alpha (1, 1, 128) torch.Size([128])\n",
      "coord_head.0.convs.0.weight depthwise_conv2d_15/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "coord_head.0.convs.0.bias depthwise_conv2d_15/Bias (128,) torch.Size([128])\n",
      "coord_head.0.convs.1.weight conv2d_16/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "coord_head.0.convs.1.bias conv2d_16/Bias (128,) torch.Size([128])\n",
      "coord_head.0.act.weight p_re_lu_16/Alpha (1, 1, 128) torch.Size([128])\n",
      "coord_head.1.convs.0.weight depthwise_conv2d_16/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "coord_head.1.convs.0.bias depthwise_conv2d_16/Bias (128,) torch.Size([128])\n",
      "coord_head.1.convs.1.weight conv2d_17/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "coord_head.1.convs.1.bias conv2d_17/Bias (128,) torch.Size([128])\n",
      "coord_head.1.act.weight p_re_lu_17/Alpha (1, 1, 128) torch.Size([128])\n",
      "coord_head.2.convs.0.weight depthwise_conv2d_17/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "coord_head.2.convs.0.bias depthwise_conv2d_17/Bias (128,) torch.Size([128])\n",
      "coord_head.2.convs.1.weight conv2d_18/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "coord_head.2.convs.1.bias conv2d_18/Bias (128,) torch.Size([128])\n",
      "coord_head.2.act.weight p_re_lu_18/Alpha (1, 1, 128) torch.Size([128])\n",
      "coord_head.3.weight conv2d_19/Kernel (32, 1, 1, 128) torch.Size([32, 128, 1, 1])\n",
      "coord_head.3.bias conv2d_19/Bias (32,) torch.Size([32])\n",
      "coord_head.4.weight p_re_lu_19/Alpha (1, 1, 32) torch.Size([32])\n",
      "coord_head.5.convs.0.weight depthwise_conv2d_18/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
      "coord_head.5.convs.0.bias depthwise_conv2d_18/Bias (32,) torch.Size([32])\n",
      "coord_head.5.convs.1.weight conv2d_20/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
      "coord_head.5.convs.1.bias conv2d_20/Bias (32,) torch.Size([32])\n",
      "coord_head.5.act.weight p_re_lu_20/Alpha (1, 1, 32) torch.Size([32])\n",
      "coord_head.6.weight conv2d_21/Kernel (1404, 3, 3, 32) torch.Size([1404, 32, 3, 3])\n",
      "coord_head.6.bias conv2d_21/Bias (1404,) torch.Size([1404])\n",
      "conf_head.0.convs.0.weight depthwise_conv2d_23/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
      "conf_head.0.convs.0.bias depthwise_conv2d_23/Bias (128,) torch.Size([128])\n",
      "conf_head.0.convs.1.weight conv2d_28/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
      "conf_head.0.convs.1.bias conv2d_28/Bias (128,) torch.Size([128])\n",
      "conf_head.0.act.weight p_re_lu_26/Alpha (1, 1, 128) torch.Size([128])\n",
      "conf_head.1.weight conv2d_29/Kernel (32, 1, 1, 128) torch.Size([32, 128, 1, 1])\n",
      "conf_head.1.bias conv2d_29/Bias (32,) torch.Size([32])\n",
      "conf_head.2.weight p_re_lu_27/Alpha (1, 1, 32) torch.Size([32])\n",
      "conf_head.3.convs.0.weight depthwise_conv2d_24/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
      "conf_head.3.convs.0.bias depthwise_conv2d_24/Bias (32,) torch.Size([32])\n",
      "conf_head.3.convs.1.weight conv2d_30/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
      "conf_head.3.convs.1.bias conv2d_30/Bias (32,) torch.Size([32])\n",
      "conf_head.3.act.weight p_re_lu_28/Alpha (1, 1, 32) torch.Size([32])\n",
      "conf_head.4.weight conv2d_31/Kernel (1, 3, 3, 32) torch.Size([1, 32, 3, 3])\n",
      "conf_head.4.bias conv2d_31/Bias (1,) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for dst, src in convert.items():\n",
    "    W = get_weights(src)\n",
    "    print(dst, src, W.shape, net.state_dict()[dst].shape)\n",
    "\n",
    "    if W.ndim == 4:\n",
    "        if W.shape[0] == 1 and dst != \"conf_head.4.weight\":\n",
    "            W = W.transpose((3, 0, 1, 2))  # depthwise conv\n",
    "        else:\n",
    "            W = W.transpose((0, 3, 1, 2))  # regular conv\n",
    "    elif W.ndim == 3:\n",
    "        W = W.reshape(-1)\n",
    "    \n",
    "    new_state_dict[dst] = torch.from_numpy(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(new_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors? Then the conversion was successful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"facemesh.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
